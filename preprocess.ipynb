{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51805e47",
   "metadata": {},
   "source": [
    "I am using 2 Data Sources:\n",
    "Plant Village: Accessed via TensorFlow Datasets (plant_village), with a local fallback in case of TFDS access issues. (https://www.tensorflow.org/datasets/catalog/plant_village)\n",
    "Crop Recommendation: Sourced from Kaggle and stored locally as ./dataset/Crop_recommendation.csv.\n",
    "(https://www.kaggle.com/datasets/siddharthss/crop-recommendation-dataset)\n",
    "\n",
    "This code processes two datasets to provide agricultural recommendations. The Crop Recommendation Dataset contains static soil and environmental data, including:\n",
    "\n",
    "N: Soil Nitrogen content (kg/ha), vital for plant growth and leaf development.\n",
    "P: Soil Phosphorus content (kg/ha), crucial for root development and energy transfer.\n",
    "K: Soil Potassium content (kg/ha), important for water regulation and disease resistance.\n",
    "\n",
    "\n",
    "The Plant Village Dataset contains images of plant disease states. \n",
    "Neither dataset includes timestamp data since they focus on static conditions or single-point-in-time observations.\n",
    "\n",
    "The primary objective is to preprocess and cluster these datasets. This will help identify common disease patterns from Plant Village and group similar soil conditions from the Crop Recommendation data. The insights gained will then be used by a large language model (LLM) to generate practical advisory messages, such as pest control recommendations for specific crops like apples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9d479",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "This section imports necessary Python libraries for data processing, machine learning, and visualization. It also configures TensorFlow logging to debug mode to help diagnose potential issues with dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c193468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501f31a",
   "metadata": {},
   "source": [
    "TFDS (TensorFlow Datasets): A library providing easy access to datasets like Plant Village, enabling online streaming without manual downloads, though it may fail due to network issues, requiring a mock data fallback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c0ddb",
   "metadata": {},
   "source": [
    "Step 2: Define Severity Mapping for Plant Village\n",
    "This section defines a dictionary (severity_map) that maps Plant Village disease labels to heuristic severity scores (0 to 1), where 0 represents no disease (healthy) and higher values indicate more severe diseases (e.g., scab=0.7, late_blight=0.8). This mapping is used to assign realistic severity scores to images, replacing the previous random approach, to improve clustering accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "267e52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_map = {\n",
    "    'healthy': 0.0,\n",
    "    'early_blight': 0.3,\n",
    "    'common_rust': 0.3,\n",
    "    'leaf_spot': 0.4,\n",
    "    'spider_mites': 0.4,\n",
    "    'powdery_mildew': 0.4,\n",
    "    'gray_leaf_spot': 0.4,\n",
    "    'northern_leaf_blight': 0.4,\n",
    "    'late_blight': 0.8,\n",
    "    'scab': 0.7,\n",
    "    'black_rot': 0.7,\n",
    "    'bacterial_spot': 0.6,\n",
    "    'target_spot': 0.6,\n",
    "    'mosaic_virus': 0.7,\n",
    "    'yellow_leaf_curl_virus': 0.7,\n",
    "    'leaf_scorch': 0.6,\n",
    "    'leaf_mold': 0.5,\n",
    "    'septoria_leaf_spot': 0.5,\n",
    "    'esca_(black_measles)': 0.6,\n",
    "    'isariopsis_leaf_spot': 0.5,\n",
    "    'cedar_apple_rust': 0.5,\n",
    "    'apple_rust': 0.5,\n",
    "    'blight': 0.8,\n",
    "    'rust': 0.5,\n",
    "    'anthracnose': 0.6,\n",
    "    'verticillium_wilt': 0.6,\n",
    "    'brown_spot': 0.5,\n",
    "    'downy_mildew': 0.6,\n",
    "    'phytophthora_infestans': 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31457081",
   "metadata": {},
   "source": [
    "Step 3: Configure TFDS Directory for Plant Village\n",
    "This section sets up a custom directory (F:/Personal/PrecisionAgriculture/tfds_data) to store TensorFlow Datasets (TFDS) data for the Plant Village Dataset, ensuring write permissions on Windows. It also disables Google Cloud Storage to enforce local storage, which helps manage potential network issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f53de432",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds_dir = 'F:/Personal/PrecisionAgriculture/tfds_data'\n",
    "os.makedirs(tfds_dir, exist_ok=True)\n",
    "tfds.core.utils.gcs_utils._is_gcs_disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00119888",
   "metadata": {},
   "source": [
    "Step 4: Load Crop Recommendation Dataset\n",
    "This section loads the Crop Recommendation Dataset from a CSV file (./dataset/Crop_recommendation.csv) into a pandas DataFrame. It checks if the file exists, raising an error if not, to ensure the dataset is available for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59940f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './dataset/Crop_recommendation.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"{csv_path} not found. Download from Kaggle.\")\n",
    "df_crop = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f0f76",
   "metadata": {},
   "source": [
    "Step 5: Verify Features for Crop Recommendation Dataset\n",
    "This section ensures the Crop Recommendation Dataset contains the expected columns (N, P, K, temperature, humidity, ph, rainfall, label). If any are missing, it raises an error. It also adds a plot_id column (1 to 2200) for unique identification of each data entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f4fd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']\n",
    "if not all(col in df_crop.columns for col in expected_columns):\n",
    "    raise ValueError(\"CSV missing expected columns.\")\n",
    "df_crop = df_crop[expected_columns]\n",
    "df_crop['plot_id'] = range(1, len(df_crop) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbfa88",
   "metadata": {},
   "source": [
    "Step 6: Handle Missing Values for Crop Recommendation Dataset\n",
    "This section handles missing values in the numerical columns (N, P, K, ph, temperature, humidity, rainfall) of the Crop Recommendation Dataset by imputing them with the median value of each column, ensuring data integrity for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04b66aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['N', 'P', 'K', 'ph', 'temperature', 'humidity', 'rainfall']\n",
    "df_crop[numerical_cols] = df_crop[numerical_cols].fillna(df_crop[numerical_cols].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77442c2",
   "metadata": {},
   "source": [
    "Step 7: Encode and Normalize Crop Recommendation Dataset\n",
    "This section preprocesses the Crop Recommendation Dataset by:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05cfda",
   "metadata": {},
   "source": [
    "One-hot encoding the label column (crop types, e.g., apple, maize) into binary columns (e.g., crop_type_apple, crop_type_maize) to enable numerical analysis.\n",
    "Concatenating the encoded columns with the original DataFrame and dropping the label column.\n",
    "Normalizing the numerical columns (N, P, K, ph, temperature, humidity, rainfall) to a [0,1] range using MinMaxScaler to prepare for DBSCAN clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b3b9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "crop_encoded = encoder.fit_transform(df_crop[['label']])\n",
    "df_crop_encoded = pd.DataFrame(crop_encoded, columns=encoder.get_feature_names_out())\n",
    "df_crop = pd.concat([df_crop.drop('label', axis=1), df_crop_encoded], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_crop[numerical_cols] = scaler.fit_transform(df_crop[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310a626",
   "metadata": {},
   "source": [
    "Step 8: Save Crop Recommendation Processed Data\n",
    "This section saves the preprocessed Crop Recommendation DataFrame to a CSV file (crop_recommendation_processed.csv) and prints a sample of the processed data (first 5 rows) to verify the preprocessing steps, ensuring the data is ready for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0576a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop Recommendation Processed Sample:\n",
      "          N         P      K  temperature  humidity        ph  rainfall  \\\n",
      "0  0.642857  0.264286  0.190     0.345886  0.790267  0.466264  0.656458   \n",
      "1  0.607143  0.378571  0.180     0.371445  0.770633  0.549480  0.741675   \n",
      "2  0.428571  0.357143  0.195     0.406854  0.793977  0.674219  0.875710   \n",
      "3  0.528571  0.214286  0.175     0.506901  0.768751  0.540508  0.799905   \n",
      "4  0.557143  0.264286  0.185     0.324378  0.785626  0.641291  0.871231   \n",
      "\n",
      "   plot_id  label_apple  label_banana  ...  label_mango  label_mothbeans  \\\n",
      "0        1          0.0           0.0  ...          0.0              0.0   \n",
      "1        2          0.0           0.0  ...          0.0              0.0   \n",
      "2        3          0.0           0.0  ...          0.0              0.0   \n",
      "3        4          0.0           0.0  ...          0.0              0.0   \n",
      "4        5          0.0           0.0  ...          0.0              0.0   \n",
      "\n",
      "   label_mungbean  label_muskmelon  label_orange  label_papaya  \\\n",
      "0             0.0              0.0           0.0           0.0   \n",
      "1             0.0              0.0           0.0           0.0   \n",
      "2             0.0              0.0           0.0           0.0   \n",
      "3             0.0              0.0           0.0           0.0   \n",
      "4             0.0              0.0           0.0           0.0   \n",
      "\n",
      "   label_pigeonpeas  label_pomegranate  label_rice  label_watermelon  \n",
      "0               0.0                0.0         1.0               0.0  \n",
      "1               0.0                0.0         1.0               0.0  \n",
      "2               0.0                0.0         1.0               0.0  \n",
      "3               0.0                0.0         1.0               0.0  \n",
      "4               0.0                0.0         1.0               0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "df_crop.to_csv('crop_recommendation_processed.csv', index=False)\n",
    "print(\"Crop Recommendation Processed Sample:\")\n",
    "print(df_crop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00388c",
   "metadata": {},
   "source": [
    "Plant Village Dataset Preprocessing\n",
    "\n",
    "The Plant Village Dataset is streamed online via TensorFlow Datasets (tfds.load), so images are not stored locally but accessed during runtime. If TFDS fails, mock data is used instead, simulating image features (e.g., HSV values, severity) without actual images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1adc64",
   "metadata": {},
   "source": [
    "Step 9: Define Function to Load Plant Village Dataset\n",
    "This section defines a function (load_plant_village) to load the Plant Village Dataset via TensorFlow Datasets (TFDS). It attempts to stream the dataset online with 3 retries, using a timeout of 120 seconds. If TFDS fails, it generates mock data (1000 entries) with random crop types, disease labels, heuristic severity scores (via severity_map), and mock HSV values, ensuring data availability for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7dc24335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_plant_village():\n",
    "    import cv2\n",
    "    data_dir = 'F:/Personal/PrecisionAgriculture/tfds_data/plant_village'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"{data_dir} not found. Ensure Plant Village images are downloaded and stored in this directory.\")\n",
    "    \n",
    "    plant_data = []\n",
    "    image_count = 0\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if image_count >= 1000:\n",
    "            break\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        crop_type = folder.split('___')[0]\n",
    "        disease_label = folder.split('___')[1]\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            if image_count >= 1000:\n",
    "                break\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            img = cv2.imread(img_path)  # Loads image as uint8 (values in [0, 255])\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, (224, 224))  # Still uint8\n",
    "            img = img / 255.0  # Converts to float64 (values in [0, 1])\n",
    "            img = img.astype(np.float32)\n",
    "            hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Fails because img is float64\n",
    "            hsv_mean = np.mean(hsv_img, axis=(0, 1))\n",
    "            severity = severity_map.get(disease_label, 0.5)\n",
    "            plant_data.append({\n",
    "                'image_id': f'img_{image_count+1}',\n",
    "                'crop_type': crop_type,\n",
    "                'disease_label': disease_label,\n",
    "                'severity': severity,\n",
    "                'hsv_h': hsv_mean[0],\n",
    "                'hsv_s': hsv_mean[1],\n",
    "                'hsv_v': hsv_mean[2]\n",
    "            })\n",
    "            image_count += 1\n",
    "    df_plant = pd.DataFrame(plant_data)\n",
    "    return df_plant, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb748bf2",
   "metadata": {},
   "source": [
    "Step 10: Load and Process Plant Village Dataset\n",
    "This section loads the Plant Village Dataset using the load_plant_village function. If TFDS data is available, it processes 1000 images by:\n",
    "\n",
    "Resizing images to 224x224 pixels and normalizing pixel values to [0,1].\n",
    "Computing heuristic severity using severity_map based on the disease label.\n",
    "Calculating mean HSV color metrics (hsv_h, hsv_s, hsv_v).\n",
    "Extracting crop type and disease label from metadata (e.g., Apple___Apple_scab).\n",
    "Creating a DataFrame with the extracted features.\n",
    "If mock data is used, the DataFrame is directly provided by the load_plant_village function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee1ecbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = load_plant_village()\n",
    "\n",
    "if isinstance(ds, pd.DataFrame):\n",
    "    df_plant = ds\n",
    "    label_map = None\n",
    "else:\n",
    "    label_map = info.features['label'].names\n",
    "    def process_image(image, label):\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = image / 255.0\n",
    "        \n",
    "        crop_type = label_map[label].split('___')[0]\n",
    "        disease_label = label_map[label].split('___')[1]\n",
    "\n",
    "        severity = severity_map.get(disease_label, 0.5)\n",
    "        hsv_image = tf.image.rgb_to_hsv(image)\n",
    "        hsv_mean = tf.reduce_mean(hsv_image, axis=[0, 1]).numpy()\n",
    "        return {\n",
    "            'severity': severity,\n",
    "            'hsv_h': hsv_mean[0],\n",
    "            'hsv_s': hsv_mean[1],\n",
    "            'hsv_v': hsv_mean[2],\n",
    "            'crop_type': crop_type,\n",
    "            'disease_label': disease_label\n",
    "        }\n",
    "\n",
    "    plant_data = []\n",
    "    for i, (image, label) in enumerate(ds.take(1000)):\n",
    "        features = process_image(image, label)\n",
    "        features['image_id'] = f'img_{i+1}'\n",
    "        plant_data.append(features)\n",
    "    df_plant = pd.DataFrame(plant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0919f8d",
   "metadata": {},
   "source": [
    "Step 11: Preprocess Plant Village Dataset\n",
    "This section completes the preprocessing of the Plant Village Dataset by:\n",
    "\n",
    "Removing rows with missing values to ensure data quality.\n",
    "Normalizing the numerical features (severity, hsv_h, hsv_s, hsv_v) to a [0,1] range using MinMaxScaler, preparing the data for DBSCAN clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9326d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant.dropna(inplace=True)\n",
    "df_plant[['severity', 'hsv_h', 'hsv_s', 'hsv_v']] = scaler.fit_transform(df_plant[['severity', 'hsv_h', 'hsv_s', 'hsv_v']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd16573",
   "metadata": {},
   "source": [
    "Step 12: Save Plant Village Processed Data\n",
    "This section saves the preprocessed Plant Village DataFrame to a CSV file (plant_village_processed.csv) and prints a sample of the processed data (first 5 rows) to verify the preprocessing steps, ensuring the data is ready for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3185dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant Village Processed Sample:\n",
      "  image_id     crop_type   disease_label  severity     hsv_h     hsv_s  \\\n",
      "0    img_1  Pepper__bell  Bacterial_spot       1.0  0.698441  0.160373   \n",
      "1    img_2  Pepper__bell  Bacterial_spot       1.0  0.679488  0.215264   \n",
      "2    img_3  Pepper__bell  Bacterial_spot       1.0  0.719451  0.054814   \n",
      "3    img_4  Pepper__bell  Bacterial_spot       1.0  0.661150  0.447317   \n",
      "4    img_5  Pepper__bell  Bacterial_spot       1.0  0.564769  0.444664   \n",
      "\n",
      "      hsv_v  \n",
      "0  0.340281  \n",
      "1  0.166608  \n",
      "2  0.412886  \n",
      "3  0.379964  \n",
      "4  0.115355  \n"
     ]
    }
   ],
   "source": [
    "df_plant.to_csv('plant_village_processed.csv', index=False)\n",
    "print(\"Plant Village Processed Sample:\")\n",
    "print(df_plant.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88491a87",
   "metadata": {},
   "source": [
    "Clustering identifies patterns in the data (e.g., high-severity disease clusters in Plant Village, nutrient-deficient plots in Crop Recommendation), enabling targeted LLM advisory messages (e.g., pest control for specific crops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db572310",
   "metadata": {},
   "source": [
    "Step 13: Cluster Plant Village Dataset\n",
    "This section applies DBSCAN clustering to the Plant Village Dataset:\n",
    "\n",
    "Generate K-Distance Plot: Uses NearestNeighbors (k=5) to compute the distance to the 5th nearest neighbor for each point in the feature set (severity, hsv_h, hsv_s, hsv_v). The distances are sorted and plotted to identify the elbow point, which helps tune the eps parameter (set to 0.15). The plot is saved as plant_village_k_distance.png.\n",
    "Apply DBSCAN Clustering: Clusters the data using DBSCAN with eps=0.15 and min_samples=5, assigning cluster labels (e.g., 0, 1, -1 for noise) to each point.\n",
    "Evaluate Clusters: Prints the count of points in each cluster to assess the clustering outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19c44ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant Village Cluster Counts:\n",
      "cluster\n",
      " 0    988\n",
      "-1     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_plant = df_plant[['severity', 'hsv_h', 'hsv_s', 'hsv_v']].values\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(X_plant)\n",
    "distances, _ = neigh.kneighbors(X_plant)\n",
    "distances = np.sort(distances[:, 4])\n",
    "plt.plot(distances)\n",
    "plt.title('K-Distance Plot for Plant Village')\n",
    "plt.savefig('plant_village_k_distance.png')\n",
    "plt.close()\n",
    "\n",
    "dbscan_plant = DBSCAN(eps=0.15, min_samples=5)\n",
    "df_plant['cluster'] = dbscan_plant.fit_predict(X_plant)\n",
    "print(\"Plant Village Cluster Counts:\")\n",
    "print(df_plant['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7359a3",
   "metadata": {},
   "source": [
    "Step 14: Cluster Crop Recommendation Dataset\n",
    "This section applies DBSCAN clustering to the Crop Recommendation Dataset:\n",
    "\n",
    "Generate K-Distance Plot: Uses NearestNeighbors (k=5) to compute the distance to the 5th nearest neighbor for each point in the feature set (N, P, K, ph, temperature, humidity, rainfall). The distances are sorted and plotted to identify the elbow point, tuning the eps parameter (set to 0.3). The plot is saved as crop_recommendation_k_distance.png.\n",
    "Apply DBSCAN Clustering: Clusters the data using DBSCAN with eps=0.3 and min_samples=5, assigning cluster labels to each point.\n",
    "Evaluate Clusters: Prints the count of points in each cluster to assess the clustering outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43245705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop Recommendation Cluster Counts:\n",
      "cluster\n",
      "0    1900\n",
      "2     200\n",
      "1     100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_crop = df_crop[numerical_cols].values\n",
    "neigh.fit(X_crop)\n",
    "distances, _ = neigh.kneighbors(X_crop)\n",
    "distances = np.sort(distances[:, 4])\n",
    "plt.plot(distances)\n",
    "plt.title('K-Distance Plot for Crop Recommendation')\n",
    "plt.savefig('crop_recommendation_k_distance.png')\n",
    "plt.close()\n",
    "\n",
    "dbscan_crop = DBSCAN(eps=0.3, min_samples=5)\n",
    "df_crop['cluster'] = dbscan_crop.fit_predict(X_crop)\n",
    "print(\"Crop Recommendation Cluster Counts:\")\n",
    "print(df_crop['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15a8af",
   "metadata": {},
   "source": [
    "Summarize clusters by computing the mean of key features (e.g., severity for Plant Village, N, ph, humidity for Crop Recommendation) per cluster, formatting as text for LLM prompts (e.g., \"Apple cluster 0: severity 0.7\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922cbff",
   "metadata": {},
   "source": [
    "Step 15: Prepare Summaries for LLM Prompt\n",
    "This section prepares summaries of the clusters for LLM input:\n",
    "\n",
    "Plant Village: Groups the data by crop_type and cluster, computes the mean severity for each group, and formats a summary string (e.g., \"Apple cluster 0: severity 0.7\").\n",
    "Crop Recommendation: Derives the crop_type column from one-hot encoded columns, groups by crop_type and cluster, computes the mean of N, ph, and humidity, and formats a summary string (e.g., \"apple cluster 1: N 0.42, pH 0.45, humidity 0.71\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b3b50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_summary = df_plant.groupby(['crop_type', 'cluster']).agg({'severity': 'mean'}).reset_index()\n",
    "plant_summary['summary'] = plant_summary.apply(\n",
    "    lambda x: f\"{x['crop_type']} cluster {x['cluster']}: severity {x['severity']:.2f}\", axis=1\n",
    ")\n",
    "\n",
    "df_crop['crop_type'] = df_crop[encoder.get_feature_names_out()].idxmax(axis=1).str.replace('crop_type_', '')\n",
    "crop_summary = df_crop.groupby(['crop_type', 'cluster']).agg({\n",
    "    'N': 'mean', 'ph': 'mean', 'humidity': 'mean'\n",
    "}).reset_index()\n",
    "crop_summary['summary'] = crop_summary.apply(\n",
    "    lambda x: f\"{x['crop_type']} cluster {x['cluster']}: N {x['N']:.2f}, ph {x['ph']:.2f}, humidity {x['humidity']:.2f}\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071de9a",
   "metadata": {},
   "source": [
    "Step 16: Generate LLM Prompt\n",
    "This section generates a sample LLM prompt by combining the cluster summaries from both datasets, requesting a pest control recommendation for apple crops. The prompt is printed to verify the formatted output, which can be used with an actual LLM (e.g., OpenAI, xAI) for generating recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2ab0e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample LLM Prompt:\n",
      "\n",
      "Analyze plant disease and soil data for advisory messages:\n",
      "- Plant Disease: ['Pepper__bell cluster -1: severity 0.75', 'Pepper__bell cluster 0: severity 1.00']\n",
      "- Soil Data: ['label_apple cluster 2: N 0.15, ph 0.38, humidity 0.91', 'label_banana cluster 0: N 0.72, ph 0.39, humidity 0.77', 'label_blackgram cluster 0: N 0.29, ph 0.56, humidity 0.59', 'label_chickpea cluster 1: N 0.29, ph 0.60, humidity 0.03', 'label_coconut cluster 0: N 0.16, ph 0.38, humidity 0.94', 'label_coffee cluster 0: N 0.72, ph 0.51, humidity 0.52', 'label_cotton cluster 0: N 0.84, ph 0.53, humidity 0.77', 'label_grapes cluster 2: N 0.17, ph 0.39, humidity 0.79', 'label_jute cluster 0: N 0.56, ph 0.50, humidity 0.76', 'label_kidneybeans cluster 0: N 0.15, ph 0.35, humidity 0.09', 'label_lentil cluster 0: N 0.13, ph 0.53, humidity 0.59', 'label_maize cluster 0: N 0.56, ph 0.43, humidity 0.59', 'label_mango cluster 0: N 0.14, ph 0.35, humidity 0.42', 'label_mothbeans cluster 0: N 0.15, ph 0.52, humidity 0.45', 'label_mungbean cluster 0: N 0.15, ph 0.50, humidity 0.83', 'label_muskmelon cluster 0: N 0.72, ph 0.44, humidity 0.91', 'label_orange cluster 0: N 0.14, ph 0.55, humidity 0.91', 'label_papaya cluster 0: N 0.36, ph 0.50, humidity 0.91', 'label_pigeonpeas cluster 0: N 0.15, ph 0.36, humidity 0.39', 'label_pomegranate cluster 0: N 0.13, ph 0.45, humidity 0.89', 'label_rice cluster 0: N 0.57, ph 0.45, humidity 0.79', 'label_watermelon cluster 0: N 0.71, ph 0.47, humidity 0.83']\n",
      "Generate a pest control recommendation for apple crops.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_prompt = f\"\"\"\n",
    "Analyze plant disease and soil data for advisory messages:\n",
    "- Plant Disease: {plant_summary['summary'].tolist()}\n",
    "- Soil Data: {crop_summary['summary'].tolist()}\n",
    "Generate a pest control recommendation for apple crops.\n",
    "\"\"\"\n",
    "print(\"Sample LLM Prompt:\")\n",
    "print(llm_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
